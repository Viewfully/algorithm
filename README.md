# TMD算法

## 介绍
TMD算法仓库，刷算法使用Java语言，用于编写/存储基本、初级、中级、高级、终极算法处理编码过程。
同时还对其他算法进行原理讲解，例如：paxos、bloomfilter、zab等其他算法。
仓库还在维护过程中，请耐心等待，作者会尽最大努力完成该算法仓库的维护。
若您有问题，或者新的想法，可以提Issues或发送邮件，作者会及时回复您并尽最大努力帮助您
（注：作者目前也是菜鸟，初学阶段。算法收集于知乎、CSDN、百科等。作者只是知识的搬运工，仅部分原创）
### 资料区：
#### 排序算法可视化演示可查看 https://visualgo.net/
#### labuladong算法：
    算法小抄在线阅读： https://labuladong.gitee.io/algo/     
    github:  https://github.com/labuladong/fucking-algorithm


## 安装教程
调试运行


## 使用说明
### 〇、基础数据结构  com.structure.basic（初学者请看这里）

#### 1.数组
#### 2.链表
#### 3.树
#### 4.二叉树
#### 5.二叉搜索树（又名二叉排序数、二叉查找树）
##### 特点
    节点的左子树小于节点本身
    节点的右子树大于节点本身
    左右子树同样为二叉搜索树

下图就是一棵典型的二叉搜索树：

![Alt text](https://pic2.zhimg.com/80/v2-3042280e3b96ceb4dfcbc531c870e6ed_720w.jpg "二叉搜索树")

二叉搜索树是均衡二叉树的基础，我们看一下它的搜索步骤如何。我们要从二叉树中找到值为 58 的节点。
第一步：首先查找到根节点，值为 60 的节点。

![Alt text](https://pic3.zhimg.com/80/v2-2dc0ababf3e1af00e7d895d28324e43e_720w.jpg "搜索")

第二步：比较我们要找的值 58 与该节点的大小。
如果等于，那么恭喜，已经找到；如果小于，继续找左子树；如果大于，那么找右子树。
很明显 58<60，因此我们找到左子树的节点 56，此时我们已经定位到了节点 56。

![Alt text](https://pic3.zhimg.com/80/v2-109153f02d44a9ee81477777ae2e4046_720w.jpg "搜索")

第三步：按照第二步的规则继续找。
58>56 我们需要继续找右子树，定位到了右子树节点 58，恭喜，此时我们已经找到了。

![Alt text](https://pic2.zhimg.com/80/v2-a9316271ebef6b4f12096a25df7d3c6d_720w.jpg "搜索")

我们经过三步就已经找到了，其实就是我们平时所说的二分查找，这种二叉搜索树好像查找效率很高，但同样它也有缺陷，如下面这样的二叉搜索树。

![Alt text](https://pic3.zhimg.com/80/v2-dbbb2eda6ebdc19de2a4c938d7d1d90e_720w.jpg "搜索")












#### 6.图

### 一、稍微复杂一点的数据结构 com.structure.simple
#### 1.平衡二叉树
平衡二叉树是基于二分法的策略提高数据的查找速度的二叉树的数据结构；
##### 规则：
平衡二叉树是采用二分法思维把数据按规则组装成一个树形结构的数据，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度；  
平衡二叉树的数据结构组装过程有以下规则：

    （1）非叶子节点只能允许最多两个子节点存在。
    （2）每一个非叶子节点数据分布规则为左边的子节点小当前节点的值，右边的子节点大于当前节点的值(这里值是基于自己的算法规则而定的，比如hash值)；
    
![Alt text](https://pic1.zhimg.com/80/v2-28e39093993f673de576f57ea614d604_720w.jpg "示例")

平衡树的层级结构：因为平衡二叉树查询性能和树的层级（h高度）成反比，h值越小查询越快、为了保证树的结构左右两端数据大致平衡降低二叉树的查询难度一般
会采用一种算法机制实现节点数据结构的平衡，实现了这种算法的有比如TreeMap、红黑树，使用平衡二叉树能保证数据的左右两边的节点层级相差不会大于1,
通过这样避免树形结构由于删除增加变成线性链表影响查询效率，保证数据平衡的情况下查找数据的速度近于二分法查找；

![Alt text](https://pic4.zhimg.com/80/v2-2b52d4e523f374f41b5429cd587443db_720w.jpg "退化为链表")

##### 特点：
    （1）非叶子节点最多拥有两个子节点；
    （2）非叶子节值大于左边子节点、小于右边子节点；
    （3）树的左右两边的层级数相差不会大于1;
    （4）没有值相等重复的节点;

#### 2.B树（又称为B-树，B-Tree）
B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构;

##### 规则：
    （1）排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则；
    （2）子节点数：非叶节点的子节点数>1，且<=M ，且M>=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）；
    （3）关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2);
    （4）特别注意这一点：所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;
最后我们用一个图和一个实际的例子来理解B树（这里为了理解方便我就直接用实际字母的大小来排列C>B>A）

![Alt text](https://pic2.zhimg.com/80/v2-2c2264cc1c6c603dfeca4f84a2575901_720w.jpg "B树")

B树的查询流程：

    如上图我要从上图中找到E字母，查找流程如下
    （1）获取根节点的关键字进行比较，当前根节点关键字为M，E<M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）；
    （2）拿到关键字D和G，D<E<G 所以直接找到D和G中间的节点；
    （3）拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）；

B树的插入节点流程

    定义一个5阶树（平衡5路查找树），现在我们要把3、8、31、11、23、29、50、28 这些数字构建出一个5阶树出来;
    遵循规则：
    （1）节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须<=5-1（这里关键字数>4就要进行节点拆分）；
    （2）排序规则：满足节点本身比左边节点大，比右边节点小的排序规则;
    
先插入 3、8、31、11     
![Alt text](https://pic4.zhimg.com/80/v2-e1d65c9c6236d4768c89e8e103e12583_720w.jpg "插入流程")

再插入23、29  
![Alt text](https://pic1.zhimg.com/80/v2-66cdb6187cbc5227fd8c4aabe7282e6c_720w.jpg "插入流程")

再插入50、28  
![Alt text](https://pic1.zhimg.com/80/v2-3057eaab2b1764dd51c2a8658791cc98_720w.jpg "插入流程")

B树节点的删除  
##### 操作规则：
    （1）节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数<2就要进行节点合并）；
    （2）满足节点本身比左边节点大，比右边节点小的排序规则;
    （3）关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放；
    
![Alt text](https://pic2.zhimg.com/80/v2-a0f981fc847772cb28869927cd4fe66d_720w.jpg "删除流程")

##### 特点：
B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，
每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；
把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度;

#### 3.B+树
B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；

##### 规则
    （1）B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加；
    （2）B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样；
    （3）B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。
    （4）非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）;

![Alt text](https://pic4.zhimg.com/80/v2-5f069fd820637db1b877fdd6799a2b67_720w.jpg "B+树结构")

（百度百科算法结构示意图）  
![Alt text](https://pic2.zhimg.com/80/v2-9644d1a1f83d3e45da779f2e63c35d55_720w.jpg "B+树结构")

##### 特点
    1、B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；
    2、B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;
    3、B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。
    4、B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。
B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。

#### 4.B*树
##### 规则
    B*树是B+树的变种，相对于B+树他们的不同之处如下：
    （1）首先是关键字个数限制问题，B+树初始化的关键字初始化个数是cei(m/2)，b*树的初始化个数为（cei(2/3*m)）
    （2）B+树节点满时就会分裂，而B*树节点满时会检查兄弟节点是否满（因为每个节点都有指向兄弟的指针），如果兄弟节点未满则向兄弟节点转移关键字，如果兄弟节点已满，则从当前节点和兄弟节点各拿出1/3的数据创建一个新的节点出来；
    
##### 特点
在B+树的基础上因其初始化的容量变大，使得节点空间使用率更高，而又存有兄弟节点的指针，可以向兄弟节点转移关键字的特性使得B*树额分解次数变得更少；

![Alt text](https://pic3.zhimg.com/80/v2-e8bf8ee3230f3d39d59ce5e76a2ee32e_720w.jpg "B*树结构")



#### 5.红黑树
##### 规则
    1、节点分为红色或者黑色。
    2、根节点必为黑色。
    3、叶子节点都为黑色，且为 null。
    4、连接红色节点的两个子节点都为黑色（红黑树不会出现相邻的红色节点）。
    5、从任意节点出发，到其每个叶子节点的路径中包含相同数量的黑色节点。
    6、新加入到红黑树的节点为红色节点。
    
规则看着好像挺多，没错，因为红黑树也是均衡二叉树，需要具备自动维持平衡的性质，上面的6条就是红黑树给出的自动维持平衡所需要具备的规则。  
典型的红黑树

![Alt text](https://pic4.zhimg.com/80/v2-25a885ee91f2f43fc86ab6bf652c901f_720w.jpg "红黑树")

##### 隐藏规则
①从根节点到叶子节点的最长路径不大于最短路径的 2 倍

        怎么样的路径算最短路径？从规则 5 中，我们知道从根节点到每个叶子节点的黑色节点数量是一样的，那么纯由黑色节点组成的路径就是最短路径。
        什么样的路径算是最长路径？根据规则 4 和规则 3，若有红色节点，则必然有一个连接的黑色节点，当红色节点和黑色节点数量相同时，就是最长路径，
    也就是黑色节点（或红色节点）*2。
    
②为什么说新加入到红黑树中的节点为红色节点
    
    从规则 4 中知道，当前红黑树中从根节点到每个叶子节点的黑色节点数量是一样的，此时假如新的是黑色节点的话，必然破坏规则。
    但加入红色节点却不一定，除非其父节点就是红色节点，因此加入红色节点，破坏规则的可能性小一些。

什么情况下，红黑树的结构会被破坏呢？破坏后又怎么维持平衡，维持平衡主要通过两种方式【变色】和【旋转】，【旋转】又分【左旋】和【右旋】，两种方式可相互结合。
下面我们从插入和删除两种场景来举例说明。  
##### 红黑树节点插入  
当我们插入值为 66 的节点时，红黑树变成了这样：

![Alt text](https://pic1.zhimg.com/80/v2-5beb671720e0e312eaaf189885e24f28_720w.jpg "红黑树插入66")

很明显，这个时候结构依然遵循着上述6大规则，无需启动自动平衡机制调整节点平衡状态。
如果再向里面插入值为 51 的节点，这个时候红黑树变成了这样：

![Alt text](https://pic4.zhimg.com/80/v2-f1e87477ebedf9339a0881618434a4c7_720w.jpg "红黑树插入51")

很明显现在的结构不遵循规则 4 了，这个时候就需要启动自动平衡机制调整节点平衡状态。  
变色：我们可以通过变色的方式，使结构满足红黑树的规则：

    首先解决结构不遵循规则 4 这一点（红色节点相连，节点 49-51），需将节点 49 改为黑色。
    此时我们发现又违反了规则 5（56-49-51-XX 路径中黑色节点超过了其他路径），那么我们将节点 45 改为红色节点。
    哈哈，妹的，又违反了规则 4（红色节点相连，节点 56-45-43），那么我们将节点 56 和节点 43 改为黑色节点。
    但是我们发现此时又违反了规则 5（60-56-XX 路径的黑色节点比 60-68-XX 的黑色节点多），因此我们需要调整节点 68 为黑色。
    完成！
    
![Alt text](https://pic4.zhimg.com/80/v2-34f08f93c9d185be9d7e3e2e01becc77_720w.jpg "红黑树自平衡过程")
   
最终调整完成后的树为:

![Alt text](https://pic3.zhimg.com/80/v2-624805416372027c8fa5927219ab1e16_720w.jpg "红黑树自平衡后")

但并不是什么时候都那么幸运，可以直接通过变色就达成目的，大多数时候还需要通过旋转来解决。
如在下面这棵树的基础上，加入节点 65：

![Alt text](https://pic1.zhimg.com/80/v2-5beb671720e0e312eaaf189885e24f28_720w.jpg "红黑树添加65")

插入节点 65 后进行以下步骤：

![Alt text](https://pic2.zhimg.com/80/v2-d440787475bcda7b603a799745e25325_720w.jpg "红黑树添加65步骤")

这个时候，你会发现对于节点64无论是红色节点还是黑色节点，都会违反规则5，路径中的黑色节点始终无法达成一致，这个时候仅通过【变色】已经无法达成目的。  
我们需要通过旋转操作，当然【旋转】操作一般还需要搭配【变色】操作。旋转包括【左旋】和【右旋】。  
左旋：逆时针旋转两个节点，让一个节点被其右子节点取代，而该节点成为右子节点的左子节点。  
左旋操作步骤如下：首先断开节点PL与右子节点G的关系，同时将其右子节点的引用指向节点C2；
然后断开节点G与左子节点C2的关系，同时将G的左子节点的应用指向节点 PL。

![Alt text](https://pic2.zhimg.com/80/v2-999bd88c511e1620915195105e7f4cc1_720w.jpg "红黑树左旋过程")

右旋：顺时针旋转两个节点，让一个节点被其左子节点取代，而该节点成为左子节点的右子节点。  
右旋操作步骤如下：首先断开节点 G 与左子节点 PL 的关系，同时将其左子节点的引用指向节点 C2；然后断开节点 PL 与右子节点 C2 的关系，同时将 PL 的右子节点的应用指向节点 G。

![Alt text](https://pic3.zhimg.com/80/v2-bb92f1ed37672dc3e55375665aedd46e_720w.png "红黑树右旋过程")

无法通过变色而进行旋转的场景分为以下四种：  
第一种：左左节点旋转（LL旋转-右单旋转:左（节点）子树的左（子树）节点插入节点）  
这种情况下，父节点和插入的节点都是左节点，如下图(旋转原始图1)这种情况下，我们要插入节点 65。  
规则如下：以祖父节点【右旋】，搭配【变色】。  

![Alt text](https://pic4.zhimg.com/80/v2-e4956ff231b30684b60b95cd24c3fe9b_720w.jpg "部分红黑树")

按照规则，步骤如下：  

![Alt text](https://pic2.zhimg.com/80/v2-01f201b6d1005d7b03ef4318af418a05_720w.jpg "红黑树右旋变色过程")

第二种：左右节点旋转（LR旋转-先左后右:左（节点）子树的右（子树）节点插入节点）  
这种情况下，父节点是左节点，插入的节点是右节点，在旋转原始图 1 中，我们要插入节点 67。  
规则如下：先父节点【左旋】，然后祖父节点【右旋】，搭配【变色】。  
按照规则，步骤如下：  

![Alt text](https://pic1.zhimg.com/80/v2-9fb00a47d12848e91c8ef06edfc02f50_720w.jpg "红黑树左右节点旋转变色过程")

第三种：右左节点旋转（RL旋转-先右后左：右（节点）子树的左（子树）节点插入节点）  
这种情况下，父节点是右节点，插入的节点是左节点，如下图（旋转原始图 2）这种情况，我们要插入节点 68。  
规则如下：先父节点【右旋】，然后祖父节点【左旋】，搭配【变色】。  

![Alt text](https://pic1.zhimg.com/80/v2-9dbdd9a4260f76eefa2ba0d9948fe824_720w.jpg "部分红黑树")  
按照规则，步骤如下：
  
![Alt text](https://pic1.zhimg.com/80/v2-3a838ffb4054e06a17b7f2ea40f868fc_720w.jpg "红黑树右左节点旋转变色过程")  
  
第四种：右右节点旋转（RR旋转-左单旋转：右（节点）子树的右（子树）节点插入节点）  
这种情况下，父节点和插入的节点都是右节点，在旋转原始图 2 中，我们要插入节点 70。  
规则如下：以祖父节点【左旋】，搭配【变色】。  
按照规则，步骤如下：    

![Alt text](https://pic1.zhimg.com/80/v2-f9cdfec89ffe3a14c464cdcbedd87d24_720w.jpg "红黑树右右节点旋转变色过程")  

##### 红黑树插入总结  
![Alt text](https://pic2.zhimg.com/80/v2-efccb287f00c36f4695727f152b6f315_720w.jpg "红黑树插入总结")  

##### 红黑树节点删除:  
相比较于红黑树的节点插入，删除节点更为复杂，我们从子节点是否为 null 和红色为思考维度来讨论。  
子节点至少有一个为 null    
当待删除的节点的子节点至少有一个为 null 节点时，删除了该节点后，将其有值的节点取代当前节点即可。  
若都为 null，则将当前节点设置为 null，当然如果违反规则了，则按需调整，如【变色】以及【旋转】。
  
![Alt text](https://pic4.zhimg.com/80/v2-34e5d523d17e82b0c0dc333a0b334907_720w.jpg "红黑树删除")  

子节点都是非 null 节点  
这种情况下：  
第一步：找到该节点的前驱或者后继。  
前驱：左子树中值最大的节点（可得出其最多只有一个非 null 子节点，可能都为 null）。  
后继：右子树中值最小的节点（可得出其最多只有一个非 null 子节点，可能都为 null）。  
前驱和后继都是值最接近该节点值的节点，类似于该节点.prev=前驱，该节点.next=后继。  
第二步：将前驱或者后继的值复制到该节点中，然后删掉前驱或者后继。  
如果删除的是左节点，则将前驱的值复制到该节点中，然后删除前驱；如果删除的是右节点，则将后继的值复制到该节点中，然后删除后继。  
这相当于是一种“取巧”的方法，我们删除节点的目的是使该节点的值在红黑树上不存在。  
因此专注于该目的，我们并不关注删除节点时是否真是我们想删除的那个节点，同时我们也不需考虑树结构的变化，因为树的结构本身就会因为自动平衡机制而经常进行调整。  
前面我们已经说了，我们要删除的实际上是前驱或者后继，因此我们就以前驱为主线来讲解。  
后继的学习可参考前驱，包括下面几种情况：  
①前驱为黑色节点，并且有一个非 null 子节点  

![Alt text](https://pic4.zhimg.com/80/v2-f88b207b8c759f6e26f744364817bfb3_720w.png "红黑树删除")  

分析：因为要删除的是左节点 64，找到该节点的前驱 63；然后用前驱的值 63替换待删除节点的值 64，此时两个节点（待删除节点和前驱）的值都为 63；  
删除前驱 63，此时成为上图过程中间环节，但我们发现其不符合红黑树规则 4，因此需要进行自动平衡调整。这里直接通过【变色】即可完成。  
②前驱为黑色节点，同时子节点都为 null  

![Alt text](https://pic1.zhimg.com/80/v2-ad0bb8349bbaa62e05a5b38bed5f4c90_720w.jpg "红黑树删除-前驱节点替代")  

分析：因为要删除的是左节点 64，找到该节点的前驱 63；然后用前驱的值 63 替换待删除节点的值 64，此时两个节点（待删除节点和前驱）的值都为 63。  
删除前驱 63，此时成为上图过程中间环节，但我们发现其不符合红黑树规则 5，因此需要进行自动平衡调整。这里直接通过【变色】即可完成。  
③前驱为红色节点，同时子节点都为 null  

![Alt text](https://pic3.zhimg.com/80/v2-20c10a98dc11a5317fcfe5f798f626a6_720w.jpg "红黑树删除-前驱节点替代")  

分析：因为要删除的是左节点 64，找到该节点的前驱 63；然后用前驱的值 63替换待删除节点的值 64，此时两个节点（待删除节点和前驱）的值都为 63；删除前驱 63，树的结构并没有打破规则。  
##### 红黑树删除总结  
红黑树删除的情况比较多，但也就存在以下情况：  
删除的是根节点，则直接将根节点置为 null。
待删除节点的左右子节点都为 null，删除时将该节点置为 null。
待删除节点的左右子节点有一个有值，则用有值的节点替换该节点即可。
待删除节点的左右子节点都不为 null，则找前驱或者后继，将前驱或者后继的值复制到该节点中，然后删除前驱或者后继。
节点删除后可能会造成红黑树的不平衡，这时我们需通过【变色】+【旋转】的方式来调整，使之平衡，上面也给出了例子，建议大家多多练习，而不必背下来。

##### 总结  
本文主要介绍了红黑树的相关原理，首先红黑树的基础二叉搜索树，我们先简单说了一下二叉搜索树，并且讲了一下搜索的流程。  
然后就针对红黑树的六大规则特点，红黑树的插入操作，删除操作，都使用了大量的图形来加以说明。  
红黑树的使用非常广泛，如 TreeMap 和 TreeSet 都是基于红黑树实现的，而 JDK8 中 HashMap 当链表长度大于 8 时也会转化为红黑树。


#### 6.跳跃表    SkipListDemo
##### 原理
单链表中查询一个元素的时间复杂度为O(n)，即使该单链表是有序的，我们也不能通过2分的方式缩减时间复杂度。   

![链表](https://img-blog.csdn.net/20161205210928206)  

如上图，我们要查询元素为55的结点，必须从头结点，循环遍历到最后一个节点，不算-INF(负无穷)一共查询8次。那么用什么办法能够用更少的次数访问55呢？最直观的，当然是新开辟一条捷径去访问55。   

![一级跳跃表](https://img-blog.csdn.net/20161205211105653)

如上图，我们要查询元素为55的结点，只需要在L2层查找4次即可。在这个结构中，查询结点为46的元素将耗费最多的查询次数5次。即先在L2查询46，查询4次后找到元素55，因为链表是有序的，46一定在55的左边，所以L2层没有元素46。然后我们退回到元素37，到它的下一层即L1层继续搜索46。非常幸运，我们只需要再查询1次就能找到46。这样一共耗费5次查询。  
那么，如何才能更快的搜寻55呢？有了上面的经验，我们就很容易想到，再开辟一条捷径。

![二级跳跃表](https://img-blog.csdn.net/20161205211246498)

如上图，我们搜索55只需要2次查找即可。这个结构中，查询元素46仍然是最耗时的，需要查询5次。即首先在L3层查找2次，然后在L2层查找2次，最后在L1层查找1次，共5次。很显然，这种思想和2分非常相似，那么我们最后的结构图就应该如下图。  

![三级跳跃表](https://img-blog.csdn.net/20161205211539787)

我们可以看到，最耗时的访问46需要6次查询。即L4访问55，L3访问21、55，L2访问37、55，L1访问46。我们直觉上认为，这样的结构会让查询有序链表的某个元素更快。那么究竟算法复杂度是多少呢？

如果有n个元素，因为是2分，所以层数就应该是log n层 (本文所有log都是以2为底)，再加上自身的1层。以上图为例，如果是4个元素，那么分层为L3和L4，再加上本身的L2，一共3层；如果是8个元素，那么就是3+1层。最耗时间的查询自然是访问所有层数，耗时logn+logn，即2logn。为什么是2倍的logn呢？我们以上图中的46为例，查询到46要访问所有的分层，每个分层都要访问2个元素，中间元素和最后一个元素。所以时间复杂度为O(logn)。  
至此为止，我们引入了最理想的跳跃表，但是如果想要在上图中插入或者删除一个元素呢？比如我们要插入一个元素22、23、24……，自然在L1层，我们将这些元素插入在元素21后，那么L2层，L3层呢？我们是不是要考虑插入后怎样调整连接，才能维持这个理想的跳跃表结构。我们知道，平衡二叉树的调整是一件令人头痛的事情，左旋右旋左右旋……一般人还真记不住，而调整一个理想的跳跃表将是一个比调整平衡二叉树还复杂的操作。幸运的是，我们并不需要通过复杂的操作调整连接来维护这样完美的跳跃表。有一种基于概率统计的插入算法，也能得到时间复杂度为O(logn)的查询效率，这种跳跃表才是我们真正要实现的。

##### 时间复杂度
单链表的查找时间复杂度为：O(n)，下面分析下跳表这种数据结构的查找时间复杂度：  
我们首先考虑这样一个问题，如果链表里有n个结点，那么会有多少级索引呢？按照上面讲的，每两个结点都会抽出一个结点作为上一级索引的结点。那么第一级索引的个数大约就是N/2，第二级的索引大约就是N/4，第三级的索引就是N/8，依次类推，也就是说，第k级索引的结点个数是第k-1级索引的结点个数的1/2，那么第k级的索引结点个数为：N/(2^k)  
假设索引有h级，最高级的索引有2个结点，通过上面的公式，我们可以得到h=logN-1,如果包含原始链表这一层，整个跳表的高度就是logN,我们在跳表中查找某个数据的时候，如果每一层都要遍历m个结点，那么在跳表中查询一个数据的时间复杂度就为：O(m\*logN)。  
其实根据前面的分析，我们不难得出m=3，即每一级索引都最多只需要遍历3个结点，分析如下：  
![跳表分析](https://img-blog.csdnimg.cn/2018102921424840.png)

如上图所示，假如我们要查找的数据是x，在第k级索引中，我们遍历到y结点之后，发现x大于y，小于y后面的结点z。所以我们通过y的down指针，从第k级索引下降到第k-1级索引。在第k-1级索引中，y和z之间只有3个结点(包含y和z)。所以，我们在k-1级索引中最多需要遍历3个结点，以此类推，每一级索引都最多只需要遍历3个结点。  
因此，m=3，所以跳表查找任意数据的时间复杂度为O(logn)，这个查找的时间复杂度和二分查找是一样的，但是我们却是基于单链表这种数据结构实现的。不过，天下没有免费的午餐，这种查找效率的提升是建立在很多级索引之上的，即空间换时间的思想。  

##### 跳表的空间复杂度  
比起单纯的单链表，跳表就需要额外的存储空间去存储多级索引。假设原始链表的大小为n，那么第一级索引大约有n/2个结点，第二级索引大约有4/n个结点，依次类推，每上升一级索引结点的个数就减少一半，直到剩下最后2个结点，如下图所示，其实就是一个等比数列。  

![索引数量分析](https://img-blog.csdnimg.cn/2018102921561752.png)
这几级索引结点总和为：n/2 + n/4 + n/8 + ... + 8 + 4 + 2 = n - 2。所以跳表的空间复杂度为O(n)。也就是说如果将包含n个结点的单链表构造成跳表，我们需要额外再用接近n个结点的存储空间。    
其实从上面的分析，我们利用空间换时间的思想，已经把时间压缩到了极致，因为每一级每两个索引结点就有一个会被抽到上一级的索引结点中，所以此时跳表所需要的额外内存空间最多，即空间复杂度最高。其实我们可以通过改变抽取结点的间距来降低跳表的空间复杂度，在其时间复杂度和空间复杂度方面取一个综合性能，当然也要看具体情况，如果内存空间足够，那就可以选择最小的结点间距，即每两个索引结点抽取一个结点到上一级索引中。如果想降低跳表的空间复杂度，则可以选择每三个或者每五个结点，抽取一个结点到上级索引中。  
![三步数跳跃表](https://img-blog.csdnimg.cn/20181029220546496.png)

如上图所示，每三个结点抽取一个结点到上一级索引中，则第一级需要大约n/3个结点，第二级索引大约需要n/9个结点。每往上一级，索引的结点个数就除以3，为了方便计算，我们假设最高一级的索引结点个数为1，则可以得到一个等比数列。  

![索引数量分析](https://img-blog.csdnimg.cn/20181029220846881.png)  
通过等比数列的求和公式，总的索引结点大约是：n/3 + n /9 + n/27 + ... + 9 + 3 + 1 = n/2。尽管空间复杂度还是O(n)，但是比之前的每两个结点抽一个结点的索引构建方法，可以减少了一半的索引结点存储空间。  
实际上，在软件开发中，我们不必太在意索引占用的额外空间。在讲数据结构的时候，我们习惯性地把要处理的数据看成整数，但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。  

##### 跳表的插入
跳表插入的时间复杂度为：O(logn)，支持高效的动态插入。  
在单链表中，一旦定位好要插入的位置，插入结点的时间复杂度是很低的，就是O(1)。但是为了保证原始链表中数据的有序性，我们需要先找到要插入的位置，这个查找的操作就会比较耗时。  
对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是对于跳表来说，查找的时间复杂度为O(logn)，所以这里查找某个数据应该插入的位置的时间复杂度也是O(logn)，如下图所示：   
![跳表查找](https://img-blog.csdnimg.cn/20181030154745189.png)  

##### 跳表的删除
跳表的删除操作时间复杂度为：O(logn)，支持动态的删除。   
在跳表中删除某个结点时，如果这个结点在索引中也出现了，我们除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到删除结点的前驱结点，然后再通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点（双向链表除外）。因此跳表的删除操作时间复杂度即为O(logn)。   

##### 跳表索引动态更新
当我们不断地往跳表中插入数据时，我们如果不更新索引，就有可能出现某2个索引节点之间的数据非常多的情况，在极端情况下，跳表还会退化成单链表  
![索引更新](https://img-blog.csdnimg.cn/20181030160535359.png)  

作为一种动态数据结构，我们需要某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中的结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入和删除操作性能的下降。  
如果你了解红黑树、AVL树这样的平衡二叉树，你就会知道它们是通过左右旋的方式保持左右子树的大小平衡，而跳表是通过随机函数来维护“平衡性”。  
当我们往跳表中插入数据的时候，我们可以通过一个随机函数，来决定这个结点插入到哪几级索引层中，比如随机函数生成了值K，那我们就将这个结点添加到第一级到第K级这个K级索引中。如下图中要插入数据为6，K=2的例子  
![示例](https://img-blog.csdnimg.cn/20181030161602638.png)  

随机函数的选择是非常有讲究的，从概率上讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能的过度退化。  

##### 跳表的性质
	(1) 由很多层结构组成，level是通过一定的概率随机产生的；
    (2) 每一层都是一个有序的链表，默认是升序 ；
    (3) 最底层(Level 1)的链表包含所有元素；
    (4) 如果一个元素出现在Level i 的链表中，则它在Level i 之下的链表也都会出现； 
    (5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面


##### 实现  
先讨论插入，我们先看理想的跳跃表结构，L2层的元素个数是L1层元素个数的1/2，L3层的元素个数是L2层的元素个数的1/2，以此类推。从这里，我们可以想到，只要在插入时尽量保证上一层的元素个数是下一层元素的1/2，我们的跳跃表就能成为理想的跳跃表。那么怎么样才能在插入时保证上一层元素个数是下一层元素个数的1/2呢？很简单，抛硬币就能解决了！假设元素X要插入跳跃表，很显然，L1层肯定要插入X。那么L2层要不要插入X呢？我们希望上层元素个数是下层元素个数的1/2，所以我们有1/2的概率希望X插入L2层，那么抛一下硬币吧，正面就插入，反面就不插入。那么L3到底要不要插入X呢？相对于L2层，我们还是希望1/2的概率插入，那么继续抛硬币吧！以此类推，元素X插入第n层的概率是(1/2)的n次。这样，我们能在跳跃表中插入一个元素了。  
在此还是以上图为例：跳跃表的初试状态如下图，表中没有一个元素：   

![初始状态](https://img-blog.csdn.net/20161205212059243)
如果我们要插入元素2，首先是在底部插入元素2，如下图：   

![插入元素2](https://img-blog.csdn.net/20161205212313963)
然后我们抛硬币，结果是正面，那么我们要将2插入到L2层，如下图:   

![抛硬币决定](https://img-blog.csdn.net/20161205212409123)

继续抛硬币，结果是反面，那么元素2的插入操作就停止了，插入后的表结构就是上图所示。接下来，我们插入元素33，跟元素2的插入一样，现在L1层插入33，如下图：   

![插入元素33](https://img-blog.csdn.net/20161205212458264)
然后抛硬币，结果是反面，那么元素33的插入操作就结束了，插入后的表结构就是上图所示。接下来，我们插入元素55，首先在L1插入55，插入后如下图：   

![抛硬币决定后插入元素55](https://img-blog.csdn.net/20161205212553339)
继续抛硬币，结果又是正面，那么L3层需要插入55，如下图：   

![抛硬币决定](https://img-blog.csdn.net/20161205212712590)  
 以此类推，我们插入剩余的元素。当然因为规模小，结果很可能不是一个理想的跳跃表。但是如果元素个数n的规模很大，学过概率论的同学都知道，最终的表结构肯定非常接近于理想跳跃表。  
当然，这样的分析在感性上是很直接的，但是时间复杂度的证明实在复杂，在此我就不深究了，感兴趣的可以去看关于跳跃表的paper。再讨论删除，删除操作没什么讲的，直接删除元素，然后调整一下删除元素后的指针即可。跟普通的链表删除操作完全一样。再来讨论一下时间复杂度，插入和删除的时间复杂度就是查询元素插入位置的时间复杂度，这不难理解，所以是O(logn)。

		代码实现见 com.structure.simple.SkipListDemo
		
##### 应用
（1）Redis中的有序集合是通过跳表来实现的，当然还用到了散列表。  
（2）大部分编程语言中的Map类型都是通过红黑树实现的，我们在写程序的时候，可以直接拿过来用，不用自己再去实现一个红黑树。但是跳表并没有一个现成的实现，所以在开发中，如果要使用跳表这种数据结构，需要自己先去实现。  
（3）Lucene, elasticSearch  


### 二、基础算法（包com.basic）
#### 1.选择排序  SelectSortDemo    O(n^2)    不稳定
    执行步骤：
        1、首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置。
        2、再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
        3、重复第二步，直到所有元素均排序完毕。
    时间复杂度：
        选择排序的交换操作介于 0 和 (n - 1)次之间。选择排序的比较操作为 n (n - 1） / 2 次之间。
    选择排序的赋值操作介于 0 和 3 (n - 1） 次之间。比较次数O(n^2)，比较次数与关键字的初始状态无关，
    总的比较次数N=(n-1）+(n-2）+...+1=n*(n-1）/2。交换次数O(n），最好情况是，已经有序，交换0次；
    最坏情况交换n-1次，逆序交换n/2次。交换次数比冒泡排序少多了，由于交换所需CPU时间比比较所需的CPU时间多，
    n值较小时，选择排序比冒泡排序快。
    稳定性：
        选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，
    依次类推，直到第n-1个元素，第n个元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，
    如果一个元素比当前元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么交换后稳定性就被破坏了。
    举个例子，序列5 8 5 2 9，我们知道第一遍选择第1个元素5会和2交换，那么原序列中两个5的相对前后顺序就被破坏了，
    所以选择排序是一个不稳定的排序算法。    
#### 2.冒泡排序  BubbleSortDemo    O(n^2)      稳定
    执行步骤：
        1、比较相邻的元素，如果前一个比后一个大，交换之。
        2、第一趟排序第1个和第2个一对，比较与交换，随后第2个和第3个一对比较交换，这样直到倒数第2个和最后1个，将最大的数移动到最后一位。
        3、第二趟将第二大的数移动至倒数第二位...... 因此需要n-1趟；
    时间复杂度：
        若文件的初始状态是正序的，一趟扫描即可完成排序。所需的关键字比较次数C和记录移动次数M均达到最小值：Cmin = n-1，Mmin = 0
    所以，冒泡排序最好的时间复杂度为O(n)。若初始文件是反序的，需要进行n-1趟排序。
    每趟排序要进行n-i次关键字的比较(1≤i≤n-1)，且每次比较都必须移动记录三次来达到交换记录位置。在这种情况下，比较和移动次数均达到最大值：
    Cmax = n(n-1)/2 = O(n^2)    Mmax = 3n(n-1)/2 = O(n^2)冒泡排序的最坏时间复杂度为O(n^2)。
    综上，因此冒泡排序总的平均时间复杂度为O(n^2)。
    算法稳定性：
        冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，
    是不会再交换的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，
    所以相同元素的前后顺序并没有改变，所以冒泡排序是一种稳定排序算法。
#### 3.插入排序  InsertSortDemo    O(n^2)      稳定
    执行步骤：
        1、假设前面 n-1(其中 n>=2)个数已经是排好顺序的，现将第 n 个数插到前面已经排好的序列中，然后找到合适自己的位置，
        使得插入第n个数的这个序列也是排好顺序的。
        2、按照此法对所有元素进行插入，直到整个序列排为有序的过程，称为插入排序。
    时间复杂度：
        在插入排序中，当待排序数组是有序时，是最优的情况，只需当前数跟前一个数比较一下就可以了，这时一共需要比较N- 1次，时间复杂度为O(n)。
    最坏的情况是待排序数组是逆序的，此时需要比较次数最多，总次数记为：1+2+3+…+N-1，所以，插入排序最坏情况下的时间复杂度为O(n^2)。
    平均来说，A[1..j-1]中的一半元素小于A[j]，一半元素大于A[j]。插入排序在平均情况运行时间与最坏情况运行时间一样，是输入规模的二次函数。
    空间复杂度：插入排序的空间复杂度为常数阶O(1)
    稳定性分析：
        如果待排序的序列中存在两个或两个以上具有相同关键词的数据，排序后这些数据的相对次序保持不变，即它们的位置保持不变，
    通俗地讲，就是两个相同的数的相对顺序不会发生改变，则该算法是稳定的；如果排序后，数据的相对次序发生了变化，则该算法是不稳定的。
    关键词相同的数据元素将保持原有位置不变，所以该算法是稳定的

#### 4.归并排序  MergeSortDemo     O(N * logN)     稳定
    执行流程：
        1、申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；
        2、设定两个指针，最初位置分别为两个已经排序序列的起始位置；
        3、比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；
        4、重复步骤3直到某一指针达到序列尾；
        5、将另一序列剩下的所有元素直接复制到合并序列尾。
    复杂度
        归并排序比较占用内存，但却是一种效率高且稳定的算法。
    改进归并排序在归并时先判断前段序列的最大值与后段序列最小值的关系再确定是否进行复制比较。如果前段序列的最大值小于等于后段序列最小值，
    则说明序列可以直接形成一段有序序列不需要再归并，反之则需要。所以在序列本身有序的情况下时间复杂度可以降至O(n)
    TimSort可以说是归并排序的终极优化版本，主要思想就是检测序列中的天然有序子段（若检测到严格降序子段则翻转序列为升序子段）。
    在最好情况下无论升序还是降序都可以使时间复杂度降至为O(n)，具有很强的自适应性。
    	****		最好时间复杂度		最坏时间复杂度		平均时间复杂度		空间复杂度		稳定性
    传统归并排序	        O(nlogn)		O(nlogn)		O(nlogn)		T(n)			稳定
    改进归并排序      	O(n)			O(nlogn)		O(nlogn)		T(n)			稳定
    TimSort			O(n)			O(nlogn)		O(nlogn)		T(n)			稳定

    Master表达式推导
    T(N) = a*T(N/b) + O(N^d)
       1) log(b,a) > d 时间复杂度为 O(N^log(b,a))
       2) log(b,a) = d 时间复杂度为 O(N^d * logN)
       3) log(b,a) < d 时间复杂度为 O(N^d)
    归并排序可通过该表达式推出时间复杂度
    仅查看递归方法 {@link InsertSortDemo#process} 的一层即可，不需要看递归多层计算
    可得 Master 表达式为
    T(N) = 2 * T(N/2) + O(N^1)
    a = 2, b = 2,d = 1
    log(2,2) = 1
    可得出时间复杂度为 O(N * logN)
   
#### 5.二叉查找、二叉搜索、折半算法（多种叫法） BiSearchDemo    O(logN) 
    执行流程：
        1、取中间位置的值与目标值进行比对
        2、若目标值大于（小于）中间值，则从数组右侧（左侧）中查找。否则则从数组左侧（右侧）中进行查找
        3、重复执行1、2步骤，直到运行完成
    复杂度：
        由于开始比较都是从最中间位置的数组值进行比较，所以树的高度h总是维持在 O(logN) 或 O(logN)+1。
        所以每次搜索目标值是最差的情况下，时间复杂度为O(logN)




### 三、初级算法
### 四、中级算法
### 五、高级算法
### 六、终级算法
### 七、其他算法（包com.other）
#### 1.布隆过滤器  BloomFilterDemo
##### 1.1布隆过滤器简介
当你往简单数组或列表中插入新数据时，将不会根据插入项的值来确定该插入项的索引值。
这意味着新插入项的索引值与数据值之间没有直接关系。这样的话，
当你需要在数组或列表中搜索相应值的时候，你必须遍历已有的集合。
若集合中存在大量的数据，就会影响数据查找的效率。
针对这个问题，你可以考虑使用哈希表。利用哈希表你可以通过对 “值” 
进行哈希处理来获得该值对应的键或索引值，然后把该值存放到列表中对应的索引位置。
这意味着索引值是由插入项的值所确定的，当你需要判断列表中是否存在该值时，
只需要对值进行哈希处理并在相应的索引位置进行搜索即可，这时的搜索速度是非常快的。

![Alt text](https://pic3.zhimg.com/80/v2-ba324df953f121b077f7bdc2a6109f0a_720w.jpg "实现流程")

根据定义，布隆过滤器可以检查值是 “可能在集合中” 还是 “绝对不在集合中”。“可能” 表示有一定的概率，也就是说可能存在一定为误判率。那为什么会存在误判呢？
下面我们来分析一下具体的原因。布隆过滤器（Bloom Filter）本质上是由长度为 m 的位向量或位列表（仅包含 0 或 1 位值的列表）组成，
最初所有的值均设置为 0，如下图所示。

![Alt text](https://pic2.zhimg.com/80/v2-3590d269c6cd9d5be764b4bc79335da5_720w.jpg "位图")

为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”。在前面所提到的哈希表中，
我们使用的是单个哈希函数，因此只能输出单个索引值。而对于布隆过滤器来说，我们将使用多个哈希函数，这将会产生多个索引值。

![Alt text](https://pic4.zhimg.com/80/v2-8c28b1d5990396202a05430bde51511b_720w.jpg "位图")

如上图所示，当输入 “semlinker” 时，预设的 3 个哈希函数将输出 2、4、6，我们把相应位置 1。假设另一个输入 ”kakuqo“，哈希函数输出 3、4 和 7。
你可能已经注意到，索引位 4 已经被先前的 “semlinker” 标记了。
此时，我们已经使用 “semlinker” 和 ”kakuqo“ 两个输入值，填充了位向量。当前位向量的标记状态为：

![Alt text](https://pic2.zhimg.com/80/v2-9cfe294a29af4209e476fccfae466d7d_720w.jpg "位图")

当对值进行搜索时，与哈希表类似，我们将使用 3 个哈希函数对 ”搜索的值“ 进行哈希运算，并查看其生成的索引值。假设，当我们搜索 ”fullstack“ 时，
3 个哈希函数输出的 3 个索引值分别是 2、3 和 7：

![Alt text](https://pic2.zhimg.com/80/v2-9a3dec489430cffd38b310c33242bf51_720w.jpg "位图")

从上图可以看出，相应的索引位都被置为 1，这意味着我们可以说 ”fullstack“ 可能已经插入到集合中。事实上这是误报的情形，
产生的原因是由于哈希碰撞导致的巧合而将不同的元素存储在相同的比特位上。幸运的是，布隆过滤器有一个可预测的误判率（FPP）：

![Alt text](https://pic4.zhimg.com/80/v2-af6d3aff3d1e50759226610d2c469b2b_720w.jpg "计算公式")

    n 是已经添加元素的数量；
    k 哈希的次数；
    m 布隆过滤器的长度（如比特数组的大小）
    
极端情况下，当布隆过滤器没有空闲空间时（满），每一次查询都会返回 true 。这也就意味着 m 的选择取决于期望预计添加元素的数量 n ，并且 m 需要远远大于 n 。
实际情况中，布隆过滤器的长度 m 可以根据给定的误判率（FFP）的和期望添加的元素个数 n 的通过如下公式计算：

![Alt text](https://pic3.zhimg.com/80/v2-19ddb2632e68e2666fd09e3c5441f542_720w.jpg "计算公式")

了解完上述的内容之后，我们可以得出一个结论，当我们搜索一个值的时候，若该值经过 K 个哈希函数运算后的任何一个索引位为 ”0“，那么该值肯定不在集合中。
但如果所有哈希索引值均为 ”1“，则只能说该搜索的值可能存在集合中。
##### 1.2布隆过滤器应用
    ①在实际工作中，布隆过滤器常见的应用场景如下：
    ②网页爬虫对 URL 去重，避免爬取相同的 URL 地址；
    ③反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱；
    ④Google Chrome 使用布隆过滤器识别恶意 URL；
    ⑤Medium 使用布隆过滤器避免推荐给用户已经读过的文章；
    ⑥Google BigTable，Apache HBbase 和 Apache Cassandra 使用布隆过滤器减少对不存在的行和列的查找。 
    除了上述的应用场景之外，布隆过滤器还有一个应用场景就是解决缓存穿透的问题。所谓的缓存穿透就是服务调用方每次都是查询不在缓存中的数据，
    这样每次服务调用都会到数据库中进行查询，如果这类请求比较多的话，就会导致数据库压力增大，这样缓存就失去了意义。







## 参与贡献


## 特技

